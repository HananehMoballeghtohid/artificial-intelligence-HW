{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de6c89a8",
   "metadata": {},
   "source": [
    "# Quoridor Game Rules (Implementation)\n",
    "## Board\n",
    "\n",
    "9 × 9 grid of cells.\n",
    "\n",
    "Rows numbered 1–9 from top to bottom.\n",
    "\n",
    "Columns numbered 1–9 from left to right.\n",
    "\n",
    "## Players\n",
    "\n",
    "Two players: MAX (player 1) and MIN (player 2).\n",
    "\n",
    "Each player has:\n",
    "\n",
    "- One pawn.\n",
    "\n",
    "- 10 walls.\n",
    "\n",
    "### Starting Positions\n",
    "\n",
    "MAX pawn: row 1, column 5.\n",
    "\n",
    "MIN pawn: row 9, column 5.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "MAX wins by reaching row 9.\n",
    "\n",
    "MIN wins by reaching row 1.\n",
    "\n",
    "## Pawns\n",
    "\n",
    "Can move to adjacent squares: up, down, left, right.\n",
    "\n",
    "Can jump over opponent if directly adjacent and no wall in between.\n",
    "\n",
    "Can move diagonally if the direct jump over opponent is blocked by a wall.\n",
    "\n",
    "Cannot move outside the board or into a square blocked by a wall.\n",
    "\n",
    "## Walls\n",
    "\n",
    "Each player can place walls until they have none left.\n",
    "\n",
    "Walls can be horizontal (H) or vertical (V).\n",
    "\n",
    "Each wall blocks two passages between cells.\n",
    "\n",
    "Walls cannot overlap any existing wall.\n",
    "\n",
    "Walls cannot completely block a path for either player; there must always be at least one valid path from each pawn to its goal row.\n",
    "\n",
    "Once placed, walls cannot be moved or removed.\n",
    "\n",
    "## Turns\n",
    "\n",
    "Players alternate turns.\n",
    "\n",
    "On a turn, a player may:\n",
    "\n",
    "Move their pawn according to the movement rules.\n",
    "\n",
    "Place a wall according to the placement rules.\n",
    "\n",
    "## Game End\n",
    "\n",
    "The game ends when one pawn reaches the opponent’s starting row.\n",
    "\n",
    "The player who reaches the goal row first wins.\n",
    "\n",
    "## Notes\n",
    "\n",
    "Anchors (row, column) are an implementation detail for walls, representing the top-left cell of a wall.\n",
    "\n",
    "Legal moves are automatically calculated to enforce rules.\n",
    "\n",
    "Wall placement conflicts and path-blocking are checked programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703d7620",
   "metadata": {},
   "source": [
    "# AI Game Agent Overview\n",
    "\n",
    "**State and Action Designer**  \n",
    "Defines the game environment, including pawns, walls, and legal moves. It utilizes a frozen dataclass for the state to enable efficient hashing and state-space exploration, ensuring structured transitions between players.\n",
    "\n",
    "**Heuristic Evaluation**  \n",
    "Computes the game-state value based on the relative distance to the goal. It employs an optimized Breadth-First Search (BFS) that pre-calculates edge connectivity based on current wall positions, significantly reducing the overhead of pathfinding during deep searches. We minimize the usage of walls and also prefer going forward instead of backward.\n",
    "\n",
    "**Minimax Implementation**  \n",
    "Recursive search algorithm that explores all possible moves to a specified depth, selecting the optimal move assuming both players act rationally. Counts examined nodes for performance tracking.\n",
    "\n",
    "**Alpha−Beta Pruning**  \n",
    "An optimized recursive search that identifies the best move by maintaining $\\alpha$ (the best score for the maximizer) and $\\beta$ (the best score for the minimizer). By passing these bounds through the search tree, the agent eliminates subtrees that cannot influence the final decision, drastically improving performance.\n",
    "\n",
    "**Move Ordering & Performance**\n",
    "To maximize pruning efficiency, the agent uses a priority-based move sorter at each node. By exploring promising moves first—such as pawn movements toward the goal—the $\\alpha$ and $\\beta$ bounds tighten earlier in the search. The system tracks examined_nodes and pruned_nodes to quantify the computational savings gained from these optimizations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a77bf5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87626ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from state import State\n",
    "from logic import legal_moves, apply, is_terminal\n",
    "import random\n",
    "from playpiece import Pawn, Wall\n",
    "  \n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "617dc979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State(p1=Pawn(row=1, col=5, owner='MAX'), p2=Pawn(row=9, col=5, owner='MIN'), p1_walls=10, p2_walls=10, walls=frozenset(), active_player='MAX')\n",
      "   1 2 3 4 5 6 7 8 9\n",
      "1 .   .   .   .   1   .   .   .   .\n",
      "                                   \n",
      "2 .   .   .   .   .   .   .   .   .\n",
      "                                   \n",
      "3 .   .   .   .   .   .   .   .   .\n",
      "                                   \n",
      "4 .   .   .   .   .   .   .   .   .\n",
      "                                   \n",
      "5 .   .   .   .   .   .   .   .   .\n",
      "                                   \n",
      "6 .   .   .   .   .   .   .   .   .\n",
      "                                   \n",
      "7 .   .   .   .   .   .   .   .   .\n",
      "                                   \n",
      "8 .   .   .   .   .   .   .   .   .\n",
      "                                   \n",
      "9 .   .   .   .   2   .   .   .   .\n"
     ]
    }
   ],
   "source": [
    "state = State.get_initial_state(random_turn=True)\n",
    "print(state)\n",
    "state.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fbbbb",
   "metadata": {},
   "source": [
    "## Heurisitic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b9f87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(state: State) -> float:\n",
    "    def get_blocked_edges(state: State):\n",
    "        blocked = set()\n",
    "        # Only check neighbors to keep the set small\n",
    "        for r in range(1, 10):\n",
    "            for c in range(1, 10):\n",
    "                for dr, dc in [(1, 0), (0, 1)]: # Only check South and East to avoid duplicates\n",
    "                    nr, nc = r + dr, c + dc\n",
    "                    if 1 <= nr <= 9 and 1 <= nc <= 9:\n",
    "                        for w in state.walls:\n",
    "                            if w.blocks_edge((r, c), (nr, nc)):\n",
    "                                blocked.add(((r, c), (nr, nc)))\n",
    "                                blocked.add(((nr, nc), (r, c)))\n",
    "        return blocked\n",
    "\n",
    "    blocked_edges = get_blocked_edges(state)\n",
    "\n",
    "    def shortest_path(pawn: Pawn, goal_row: int) -> int:\n",
    "        q = deque([(pawn.row, pawn.col, 0)])\n",
    "        seen = {(pawn.row, pawn.col)}\n",
    "        while q:\n",
    "            r, c, d = q.popleft()\n",
    "            if r == goal_row: return d\n",
    "            for dr, dc in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
    "                nr, nc = r + dr, c + dc\n",
    "                if 1 <= nr <= 9 and 1 <= nc <= 9:\n",
    "                    if (nr, nc) not in seen and ((r, c), (nr, nc)) not in blocked_edges:\n",
    "                        seen.add((nr, nc))\n",
    "                        q.append((nr, nc, d + 1))\n",
    "        return 100\n",
    "\n",
    "    max_dist = shortest_path(state.p1, 9)\n",
    "    min_dist = shortest_path(state.p2, 1)\n",
    "    \n",
    "    score = min_dist - max_dist\n",
    "    score += (state.p1_walls * 0.8)\n",
    "    score -= (state.p2_walls * 0.8)\n",
    "    score += (state.p1.row * 0.1)\n",
    "    score -= ((10 - state.p2.row) * 0.1)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae3580",
   "metadata": {},
   "source": [
    "### MINIMAX Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9c1d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "examined_nodes = 0\n",
    "\n",
    "def minimax(state: \"State\", depth: int, maximizing: bool) -> float:\n",
    "    global examined_nodes\n",
    "    examined_nodes += 1\n",
    "\n",
    "    if depth == 0 or is_terminal(state):\n",
    "        return evaluation(state)\n",
    "\n",
    "    moves = legal_moves(state)\n",
    "\n",
    "    if maximizing:\n",
    "        max_eval = -float('inf')\n",
    "        for move in moves:\n",
    "            new_state = apply(state, move)\n",
    "            val = minimax(new_state, depth-1, False)\n",
    "            max_eval = max(max_eval, val)\n",
    "        return max_eval\n",
    "    else:\n",
    "        min_eval = float('inf')\n",
    "        for move in moves:\n",
    "            new_state = apply(state, move)\n",
    "            val = minimax(new_state, depth-1, True)\n",
    "            min_eval = min(min_eval, val)\n",
    "        return min_eval\n",
    "\n",
    "\n",
    "def best_move(state: \"State\", depth: int) -> tuple:\n",
    "    global examined_nodes\n",
    "    examined_nodes = 0\n",
    "\n",
    "    maximizing = True if state.active_player == \"MAX\" else False\n",
    "    best_val = -float('inf') if maximizing else float('inf')\n",
    "    best_actions = []\n",
    "\n",
    "    for move in legal_moves(state):\n",
    "        new_state = apply(state, move)\n",
    "        val = minimax(new_state, depth-1, not maximizing)\n",
    "\n",
    "        if maximizing:\n",
    "            if val > best_val:\n",
    "                best_val = val\n",
    "                best_actions = [move]\n",
    "            elif val == best_val:\n",
    "                best_actions.append(move)\n",
    "        else:\n",
    "            if val < best_val:\n",
    "                best_val = val\n",
    "                best_actions = [move]\n",
    "            elif val == best_val:\n",
    "                best_actions.append(move)\n",
    "\n",
    "    chosen_move = random.choice(best_actions)\n",
    "    print(f\"Examined nodes: {examined_nodes}\")\n",
    "    return chosen_move\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fb4c700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examined nodes: 17032\n",
      "('MOVE', (2, 5))\n"
     ]
    }
   ],
   "source": [
    "best_move = best_move(state, 2)\n",
    "print(best_move)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cacee5",
   "metadata": {},
   "source": [
    "### ALPHA-BETA PRUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b92b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_moves(state: State):\n",
    "    moves = list(legal_moves(state))\n",
    "    \n",
    "    def move_priority(move):\n",
    "        if hasattr(move, 'row'): \n",
    "            goal = 9 if state.active_player == \"MAX\" else 1\n",
    "            dist_to_goal = abs(move.row - goal)\n",
    "            return 100 - dist_to_goal\n",
    "        return 0 \n",
    "    \n",
    "    return sorted(moves, key=move_priority, reverse=True)\n",
    "\n",
    "def alphabeta(state: State, depth: int, alpha: float, beta: float, maximizing: bool) -> float:\n",
    "    global examined_nodes, pruned_nodes\n",
    "    examined_nodes += 1\n",
    "\n",
    "    if depth == 0 or is_terminal(state):\n",
    "        return evaluation(state)\n",
    "\n",
    "    moves = get_ordered_moves(state)\n",
    "\n",
    "    if maximizing:\n",
    "        value = -float('inf')\n",
    "        for move in moves:\n",
    "            new_state = apply(state, move)\n",
    "            value = max(value, alphabeta(new_state, depth-1, alpha, beta, False))\n",
    "            alpha = max(alpha, value)\n",
    "            if alpha >= beta:\n",
    "                pruned_nodes += 1\n",
    "                break\n",
    "        return value\n",
    "    else:\n",
    "        value = float('inf')\n",
    "        for move in moves:\n",
    "            new_state = apply(state, move)\n",
    "            value = min(value, alphabeta(new_state, depth-1, alpha, beta, True))\n",
    "            beta = min(beta, value)\n",
    "            if beta <= alpha:\n",
    "                pruned_nodes += 1\n",
    "                break\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81a61480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examined nodes: 392, Pruned nodes: 130\n",
      "Chosen move: ('MOVE', (2, 5))\n"
     ]
    }
   ],
   "source": [
    "move = best_move_ab(state, depth=2)\n",
    "print(\"Chosen move:\", move)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1629a91",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90879fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, depth: int = 4):\n",
    "        self.depth = depth\n",
    "\n",
    "    def get_action(self, state: State):\n",
    "        global examined_nodes, pruned_nodes\n",
    "        examined_nodes = 0\n",
    "        pruned_nodes = 0\n",
    "\n",
    "        maximizing = state.active_player == \"MAX\"\n",
    "        alpha, beta = -float('inf'), float('inf')\n",
    "        best_val = -float('inf') if maximizing else float('inf')\n",
    "        best_actions = []\n",
    "        \n",
    "        moves = get_ordered_moves(state)\n",
    "\n",
    "        for move in moves:\n",
    "            new_state = apply(state, move)\n",
    "            val = alphabeta(new_state, self.depth - 1, alpha, beta, not maximizing)\n",
    "\n",
    "            if maximizing:\n",
    "                if val > best_val:\n",
    "                    best_val, best_actions = val, [move]\n",
    "                elif val == best_val:\n",
    "                    best_actions.append(move)\n",
    "                alpha = max(alpha, best_val)\n",
    "            else:\n",
    "                if val < best_val:\n",
    "                    best_val, best_actions = val, [move]\n",
    "                elif val == best_val:\n",
    "                    best_actions.append(move)\n",
    "                beta = min(beta, best_val)\n",
    "\n",
    "        if not best_actions: return None\n",
    "        \n",
    "        print(f\"Nodes Examined: {examined_nodes} | Nodes Pruned: {pruned_nodes}\")\n",
    "        return random.choice(best_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a026da37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1 2 3 4 5 6 7 8 9\n",
      "1 .   .   .   .   1   .   .   .   .\n",
      "                                   \n",
      "2 .   .   .   .   .   .   .   .   .\n",
      "                                   \n",
      "3 .   .   .   .   .   .   .   .   .\n",
      "                                   \n",
      "4 .   .   .   .   .   .   .   .   .\n",
      "                                   \n",
      "5 .   .   .   .   .   .   .   .   .\n",
      "                                   \n",
      "6 .   .   .   .   .   .   .   .   .\n",
      "                                   \n",
      "7 .   .   .   .   .   .   .   .   .\n",
      "                                   \n",
      "8 .   .   .   .   .   .   .   .   .\n",
      "                                   \n",
      "9 .   .   .   .   2   .   .   .   .\n",
      "Nodes Examined: 17426 | Nodes Pruned: 260\n",
      "Agent chooses: ('MOVE', (8, 5))\n"
     ]
    }
   ],
   "source": [
    "state = State.get_initial_state(random_turn=True)\n",
    "state.display()\n",
    "\n",
    "agent = Agent(depth=3)\n",
    "move = agent.get_action(state)\n",
    "print(\"Agent chooses:\", move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073ab9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_max = Agent(depth=3)  # MAX player\n",
    "agent_min = Agent(depth=3)  # MIN player\n",
    "\n",
    "current_state = State.get_initial_state(random_turn=True)\n",
    "current_state.display()\n",
    "\n",
    "while not is_terminal(current_state):\n",
    "    if current_state.active_player == \"MAX\":\n",
    "        move = agent_max.get_action(current_state)\n",
    "    else:\n",
    "        move = agent_min.get_action(current_state)\n",
    "\n",
    "    current_state = apply(current_state, move)\n",
    "    current_state.display()\n",
    "\n",
    "current_state.display()\n",
    "if current_state.p1.row == 9:\n",
    "    print(\"MAX wins!\")\n",
    "elif current_state.p2.row == 1:\n",
    "    print(\"MIN wins!\")\n",
    "else:\n",
    "    print('It is a draw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b305c43c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
